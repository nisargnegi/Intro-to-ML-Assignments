{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "11f67844-b20d-474e-856d-9aecd7dd2e8d",
    "_execution_state": "idle",
    "_uuid": "a954321b8c2937af9965ded91af4aa8c15343575"
   },
   "source": [
    "<H1>Data analysis and machine learning using custom Neural Network (w/o any scify libraries)</H1>\n",
    "This is my first kernel at Kaggle. I am also a beginner in data science and machine learning.\n",
    "\n",
    "To understand details and advanced concepts in ML, I thought I'll start with simple concepts for my learning or for anyone else in my position.\n",
    "\n",
    "As a result, below is a simple neural network made from scratch in python. I will be updating the text explaining the basics of the network and creating new (and simple) network for different datasets as I go along.\n",
    "\n",
    "Comments/Crits/Corrections welcome. Thanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "_cell_guid": "ee2344ec-7c3f-443f-a3f8-5c82d08e4f0a",
    "_execution_state": "idle",
    "_uuid": "9c47d27f4a970f1b38eb009ea3707116241284a1"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns # visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "#from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "374a1d1a-7180-4693-8f64-c835e3aaf6a0",
    "_execution_state": "idle",
    "_uuid": "a352d2f170140e15467b2d78486a5e7df71576bf"
   },
   "source": [
    "<H2>Load Data</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "_cell_guid": "b1dd6b67-54f5-41ed-a096-c2e62e83ee87",
    "_execution_state": "idle",
    "_uuid": "8867b483cc2f77574aa5d6e20a39861d1ad22d8a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case #</th>\n",
       "      <th>I0</th>\n",
       "      <th>PA500</th>\n",
       "      <th>HFS</th>\n",
       "      <th>DA</th>\n",
       "      <th>Area</th>\n",
       "      <th>A/DA</th>\n",
       "      <th>Max IP</th>\n",
       "      <th>DR</th>\n",
       "      <th>P</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>650.0</td>\n",
       "      <td>0.041015</td>\n",
       "      <td>0.145211</td>\n",
       "      <td>216.811330</td>\n",
       "      <td>427.534068</td>\n",
       "      <td>1.971918</td>\n",
       "      <td>33.765163</td>\n",
       "      <td>214.165979</td>\n",
       "      <td>528.699233</td>\n",
       "      <td>con</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>272.0</td>\n",
       "      <td>0.091455</td>\n",
       "      <td>0.004887</td>\n",
       "      <td>63.789380</td>\n",
       "      <td>718.946310</td>\n",
       "      <td>11.270627</td>\n",
       "      <td>20.085556</td>\n",
       "      <td>60.690729</td>\n",
       "      <td>286.920220</td>\n",
       "      <td>fad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0.034208</td>\n",
       "      <td>0.042586</td>\n",
       "      <td>301.060351</td>\n",
       "      <td>4406.154331</td>\n",
       "      <td>14.635452</td>\n",
       "      <td>67.625328</td>\n",
       "      <td>293.366920</td>\n",
       "      <td>1742.375702</td>\n",
       "      <td>adi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.174707</td>\n",
       "      <td>0.165457</td>\n",
       "      <td>98.509961</td>\n",
       "      <td>2741.032044</td>\n",
       "      <td>27.824923</td>\n",
       "      <td>49.327862</td>\n",
       "      <td>85.270010</td>\n",
       "      <td>388.977808</td>\n",
       "      <td>mas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0.069115</td>\n",
       "      <td>0.157080</td>\n",
       "      <td>385.564704</td>\n",
       "      <td>13831.724890</td>\n",
       "      <td>35.873940</td>\n",
       "      <td>157.570007</td>\n",
       "      <td>351.897477</td>\n",
       "      <td>1823.032364</td>\n",
       "      <td>adi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Case #      I0     PA500       HFS          DA          Area       A/DA  \\\n",
       "76      77   650.0  0.041015  0.145211  216.811330    427.534068   1.971918   \n",
       "30      31   272.0  0.091455  0.004887   63.789380    718.946310  11.270627   \n",
       "85      86  1800.0  0.034208  0.042586  301.060351   4406.154331  14.635452   \n",
       "50      51   310.0  0.174707  0.165457   98.509961   2741.032044  27.824923   \n",
       "94      95  1800.0  0.069115  0.157080  385.564704  13831.724890  35.873940   \n",
       "\n",
       "        Max IP          DR            P Class  \n",
       "76   33.765163  214.165979   528.699233   con  \n",
       "30   20.085556   60.690729   286.920220   fad  \n",
       "85   67.625328  293.366920  1742.375702   adi  \n",
       "50   49.327862   85.270010   388.977808   mas  \n",
       "94  157.570007  351.897477  1823.032364   adi  "
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load iris database\n",
    "data = pd.read_csv('BreastTissue.csv')\n",
    "data.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car' 'fad' 'mas' 'gla' 'con' 'adi']\n"
     ]
    }
   ],
   "source": [
    "print(data.Class.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "f4798e56-9a79-499f-904c-ad38915aa89c",
    "_uuid": "032bab9f12b63136364660442700b9912f98a76d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d9b81a4e-fd03-47b8-bef4-9ad483d7ca87",
    "_uuid": "2b646d0b1df11c98872ebd4b2d5c275734b55769"
   },
   "outputs": [],
   "source": [
    "# simple visualization to show how the inputs compare against each other\n",
    "#sns.pairplot( data=data, vars=('I0', 'PA500', 'HFS', 'DA', 'Area', 'A/DA', 'Max IP', 'DR',\n",
    "#       'P'), hue='Class' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a60e2eff-b5c4-4658-a960-d73df0e220f9",
    "_execution_state": "idle",
    "_uuid": "41b39f54acd92bd56a60ffa6d11ef81628c31cd7"
   },
   "source": [
    "<H2>Normalize the data</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "454624af-3f92-47e6-9180-c9554782427f",
    "_execution_state": "idle",
    "_uuid": "14f46347b268c98a1b04648fe5a0a69e07676e30"
   },
   "outputs": [],
   "source": [
    "df_norm = data[['I0', 'PA500', 'HFS', 'DA', 'Area', 'A/DA', 'Max IP', 'DR',\n",
    "       'P']].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "df_norm.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c24f6f1a-5815-4b92-9c4c-cfe971bdea80",
    "_uuid": "e51e08037742cc51ae6fa01a9c786f6f68fe42db"
   },
   "outputs": [],
   "source": [
    "df_norm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "48edd9b7-741f-4412-a237-89ef77a9e7b2",
    "_uuid": "733a47d4cdb2757a68eb0eae39c35947790a9dac"
   },
   "source": [
    "Convert the Species labels to indexes for use with neural network.<BR>\n",
    "Iris-setoso = 0<BR>\n",
    "Iris-versicolor = 1<BR>\n",
    "Iris-virginica = 2<BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f70e1cb2-52d0-4c78-8168-c973b0a76bf5",
    "_execution_state": "idle",
    "_uuid": "ca2dd0087b282cf4c582a451b4d28eadd8ba63f8"
   },
   "outputs": [],
   "source": [
    "target = data[['Class']].replace(['car','fad','mas','gla','con','adi'],[0,1,2,3,4,5])\n",
    "target.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "47590e72-b402-4316-a8ca-4e3d88c6940b",
    "_execution_state": "idle",
    "_uuid": "62bc8543206e1810a449421eb1c3fd6327d0097c"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_norm, target], axis=1)\n",
    "df.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3df12ee9-5e43-46bf-aa94-04c659711319",
    "_execution_state": "idle",
    "_uuid": "874d7644dcff89441e203f153869afc3b8ff8818"
   },
   "source": [
    "<H2>Mark some of the data for testing purpose.</H2>\n",
    "We'll test our network on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8affdcdc-e542-4756-a1ad-15c3f1aadb78",
    "_execution_state": "idle",
    "_uuid": "07d05b4f875907586d97b92cce4281dfe6a0085c"
   },
   "outputs": [],
   "source": [
    "train_test_per = 90/100.0\n",
    "df['train'] = np.random.rand(len(df)) < train_test_per\n",
    "df.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "20165ffd-19e5-49f6-8de6-5a2d005196a7",
    "_execution_state": "idle",
    "_uuid": "9304e29c9ad1609835c92c6d2b2beb46e80739fe"
   },
   "source": [
    "<H2>Separate train and test Data</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a6931b6b-f9dd-4620-ba3d-d70530fbec6b",
    "_execution_state": "idle",
    "_uuid": "abeac29a19187a10e5455ca84f93e6f22f1ac182"
   },
   "outputs": [],
   "source": [
    "train = df[df.train == 1]\n",
    "train = train.drop('train', axis=1).sample(frac=1)\n",
    "train.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3256e1b1-f6b2-4f16-a445-7b1f9d44a8b3",
    "_execution_state": "idle",
    "_uuid": "19595835e0b742e9a68e1039b23e32fdf2a073e9"
   },
   "outputs": [],
   "source": [
    "test = df[df.train == 0]\n",
    "test = test.drop('train', axis=1)\n",
    "test.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "11444b6c-745f-492b-a65b-9dc041d6f3f3",
    "_execution_state": "idle",
    "_uuid": "2d0fc27a78791140e749bcf5e044f277674b704a"
   },
   "outputs": [],
   "source": [
    "X = train.values[:,:9]\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "aab445d9-9bd8-4bad-a860-2687fb274d7e",
    "_execution_state": "idle",
    "_uuid": "1df984211fbc0bb972cb1961963d313883a42461"
   },
   "outputs": [],
   "source": [
    "targets = [[1,0,0,0,0,0],[0,1,0,0,0,0],[0,0,1,0,0,0],[0,0,0,1,0,0],[0,0,0,0,1,0],[0,0,0,0,0,1]]\n",
    "y = np.array([targets[int(x)] for x in train.values[:,9:10]])\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bc3e0730-244e-4b4b-b26d-23c01d4d9da7",
    "_execution_state": "idle",
    "_uuid": "85ba8014cf1bcf3581c450f362b268913a0359b0"
   },
   "source": [
    "<H2>Create backpropagating neural network</H2>\n",
    "Create 3 layers: Input, hidden and Output.\n",
    "\n",
    "Inputs = length and widths of the species<BR>\n",
    "Output = 3 values, each one indicating a species. ie Values 1, 0, 0 for the output indicates Iris-setosa<BR>\n",
    "w1 is a matrices of weight connecting Input and the hidden layer. Each node in input layer connects to each node in the hidden layer.\n",
    "\n",
    "Weight are randomized between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "141ea9e7-5e81-438b-863c-b4ecbdf99112",
    "_execution_state": "idle",
    "_uuid": "cf8502b6884e2508abe093f7c2536b2afaf5a98f"
   },
   "outputs": [],
   "source": [
    "num_inputs = len(X[0])\n",
    "hidden_layer_neurons = 12\n",
    "np.random.seed(4)\n",
    "w1 = 2*np.random.random((num_inputs, hidden_layer_neurons)) - 1\n",
    "w1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1ca5b524-25be-45bd-befc-e6ff5b330c1d",
    "_execution_state": "idle",
    "_uuid": "cb15100dd971aefffb12ea6a785f7417f16f846c"
   },
   "source": [
    "<H3>w2 are the weights of connections between hidden layer and output layer.</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f4f382b0-6c3e-4a0b-be6d-e4a3a51ab2d8",
    "_execution_state": "idle",
    "_uuid": "f1089894abdf9f9f7e576b55dcb6fde732219436"
   },
   "outputs": [],
   "source": [
    "num_outputs = len(y[0])\n",
    "w2 = 2*np.random.random((hidden_layer_neurons, num_outputs)) - 1\n",
    "w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c4c46877-3ec3-4b1d-a93f-45980e84a408",
    "_execution_state": "idle",
    "_uuid": "7a6725dc44f37a087e1c2adfa5c1d0b67bba6220"
   },
   "source": [
    "<H2>Train the network by updating the weights using backpropogation.</H2>\n",
    "This is the crux of the network. The layers are fed forward using sigmoid activation function. The weighs are then updated based on error using gradient descent.\n",
    "\n",
    "<pre>\n",
    "Forward Propagation ( use current weights to caluculate output ):\n",
    "> node activation = output from previous layer (network inputs in case of first layer) * weights\n",
    "> node output = sigmoid activation function = 1 / ( 1 + exp( node activation ) )\n",
    "\n",
    "Backpropagation ( update network weights ):\n",
    "Error calculation ( how far off we are from the expected values ):\n",
    "> derivative (different for different activation functions) = output * ( 1 - output )\n",
    "> error (for the last layer) = ( expected - output ) * derivative\n",
    "> error (for other layers) = ( error calulated previously * that layer's weight ) * derivative\n",
    "Update weight based on error caculated:\n",
    "> Weight = weight + ( output * error * learning rate )\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a2b5bca3-bd4f-4131-b746-51332550d238",
    "_uuid": "7910c728e1633a4c945cd5f5cbc13509953abc12"
   },
   "outputs": [],
   "source": [
    "# taken from> https://gist.github.com/craffel/2d727968c3aaebd10359\n",
    "def draw_neural_net(ax, left, right, bottom, top, layer_sizes):\n",
    "    '''\n",
    "    Draw a neural network cartoon using matplotilb.\n",
    "    \n",
    "    :usage:\n",
    "        >>> fig = plt.figure(figsize=(12, 12))\n",
    "        >>> draw_neural_net(fig.gca(), .1, .9, .1, .9, [4, 7, 2])\n",
    "    \n",
    "    :parameters:\n",
    "        - ax : matplotlib.axes.AxesSubplot\n",
    "            The axes on which to plot the cartoon (get e.g. by plt.gca())\n",
    "        - left : float\n",
    "            The center of the leftmost node(s) will be placed here\n",
    "        - right : float\n",
    "            The center of the rightmost node(s) will be placed here\n",
    "        - bottom : float\n",
    "            The center of the bottommost node(s) will be placed here\n",
    "        - top : float\n",
    "            The center of the topmost node(s) will be placed here\n",
    "        - layer_sizes : list of int\n",
    "            List of layer sizes, including input and output dimensionality\n",
    "    '''\n",
    "    n_layers = len(layer_sizes)\n",
    "    v_spacing = (top - bottom)/float(max(layer_sizes))\n",
    "    h_spacing = (right - left)/float(len(layer_sizes) - 1)\n",
    "    # Nodes\n",
    "    for n, layer_size in enumerate(layer_sizes):\n",
    "        layer_top = v_spacing*(layer_size - 1)/2. + (top + bottom)/2.\n",
    "        for m in range(layer_size):\n",
    "            circle = plt.Circle((n*h_spacing + left, layer_top - m*v_spacing), v_spacing/4.,\n",
    "                                color='w', ec='k', zorder=4)\n",
    "            ax.add_artist(circle)\n",
    "    # Edges\n",
    "    for n, (layer_size_a, layer_size_b) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "        layer_top_a = v_spacing*(layer_size_a - 1)/2. + (top + bottom)/2.\n",
    "        layer_top_b = v_spacing*(layer_size_b - 1)/2. + (top + bottom)/2.\n",
    "        for m in range(layer_size_a):\n",
    "            for o in range(layer_size_b):\n",
    "                line = plt.Line2D([n*h_spacing + left, (n + 1)*h_spacing + left],\n",
    "                                  [layer_top_a - m*v_spacing, layer_top_b - o*v_spacing], c='k')\n",
    "                ax.add_artist(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "db3fb84b-b86a-44a0-aa5f-29f378df7375",
    "_uuid": "4786168c2ad7a8aaf4dd7eb66bd1a71d2dade2c0"
   },
   "source": [
    "**A Graphical representations of our network will be something like below**<BR>\n",
    "The first set of 4 nodes is the input.<BR>\n",
    "The second set of 5 nodes is the hidden layer. <BR>\n",
    "The last set of 3 nodes is the output layer.<BR><BR>\n",
    "All the nodes of a layer are fully connected to all nodes of the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "728c6bfa-bba6-4b90-8f78-ef8a7020ee9c",
    "_uuid": "6a25e5e7217e0164277f4de26c7777a1a59da9d3"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.gca()\n",
    "ax.axis('off')\n",
    "draw_neural_net(ax, .1, .9, .1, .9, [9, 12, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0fc2cb9e-4bf3-4fff-91c7-cfbf9b2c23f9",
    "_uuid": "3356074e526059ddd552c4692e7150dd10c2df46"
   },
   "source": [
    "The sigmoid activation function squashes the input values between 0 and 1. This provides a consistant way for the network to deal with outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5824165c-ed04-4146-8c79-30f23d6d55c4",
    "_uuid": "4e2fe03a960e36b78dbb247925429e3a45d7a63b"
   },
   "outputs": [],
   "source": [
    "# sigmoid function representation\n",
    "_x = np.linspace( -5, 5, 50 )\n",
    "_y = 1 / ( 1 + np.exp( -_x ) )\n",
    "plt.plot( _x, _y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ff67904f-11fd-492d-8991-8a06925208b5",
    "_execution_state": "idle",
    "_uuid": "63940deaa9799c624d6b8920e934d3963bda0526"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.2 # slowly update the network\n",
    "error = []\n",
    "for epoch in range(1000):\n",
    "    # activate the first layer using the input\n",
    "    #   matrix multiplication between the input and the layer 1 weights\n",
    "    #   result is fed into a sigmoid function\n",
    "    l1 = 1/(1 + np.exp(-(np.dot(X, w1))))\n",
    "    # activate the second layer using first layer as input\n",
    "    l2 = 1/(1 + np.exp(-(np.dot(l1, w2))))\n",
    "    # find the average errorof this batch\n",
    "    #   using absolute, can use use square as well\n",
    "    er = (abs(y - l2)).mean()\n",
    "    error.append(er)\n",
    "    \n",
    "    # BACKPROPAGATION / learning!\n",
    "    # find contribution of error on each weight on the second layer\n",
    "    l2_delta = (y - l2)*(l2 * (1-l2))\n",
    "    # update each weight in the second layer slowly\n",
    "    w2 += l1.T.dot(l2_delta) * learning_rate\n",
    "    \n",
    "    # find contribution of error on each weight on the second layer w.r.t the first layer\n",
    "    l1_delta = l2_delta.dot(w2.T) * (l1 * (1-l1))\n",
    "    # udpate weights in the first layer\n",
    "    w1 += X.T.dot(l1_delta) * learning_rate\n",
    "    \n",
    "print('Error:', er)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f15115ce-e27a-4007-af4c-eed3b43dd2ac",
    "_execution_state": "idle",
    "_uuid": "e389444888b6439f032841e3607b42703b8a5219"
   },
   "source": [
    "<H2>Test the network for accuracy.</H2>\n",
    "Run the network with the updated weights from training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f1b9e52c-3e75-499c-8de2-e9fbf9f9e31d",
    "_execution_state": "idle",
    "_uuid": "4250a08db8d0ed17193ec8760f6dbbda1a8ac8bf"
   },
   "outputs": [],
   "source": [
    "X = test.values[:,:9]\n",
    "y = np.array([targets[int(x)] for x in test.values[:,9:10]])\n",
    "\n",
    "l1 = 1/(1 + np.exp(-(np.dot(X, w1))))\n",
    "l2 = 1/(1 + np.exp(-(np.dot(l1, w2))))\n",
    "\n",
    "np.round(l2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0cd83a26-b0e7-4be2-8d6e-cf72502ebd1d",
    "_uuid": "782f633989f7b013feb7bbd0417800b51130d1ec"
   },
   "source": [
    "From the above maxtrix we take the maximum value (per row), which forms our predictions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "02728c67-a8b3-4567-b60f-faa060118b59",
    "_uuid": "796c6ce3d40d175b66284c308486b35ad6e7d3a5"
   },
   "outputs": [],
   "source": [
    "yp = np.argmax(l2, axis=1) # prediction\n",
    "res = yp == np.argmax(y, axis=1)\n",
    "correct = np.sum(res)/len(res)\n",
    "\n",
    "testres = test[['Class']].replace([0,1,2,3,4,5], ['car','fad','mas','gla','con','adi'])\n",
    "\n",
    "testres['Prediction'] = yp\n",
    "testres['Prediction'] = testres['Prediction'].replace([0,1,2,3,4,5], ['car','fad','mas','gla','con','adi'])\n",
    "\n",
    "print(testres)\n",
    "print('Correct:',sum(res),'/',len(res), ':', (correct*100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
